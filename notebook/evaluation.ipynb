{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\ml-hus\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import vcf2onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2onehot(label: np.array) -> np.array:\n",
    "    thresholds = [0.25, 0.75, 1.25, 1.75]\n",
    "\n",
    "    categorical_labels = np.digitize(label, thresholds)\n",
    "\n",
    "    one_hot_encoder = to_categorical(categorical_labels)\n",
    "    \n",
    "    return one_hot_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "\t# model = load_model('../save_model/ModelCheckPoint/final_25-03-2024_02-32/model.088-0.0545-0.9746.h5')\n",
    "\tmodel = load_model('../save_model/FinalModel/final_25-03-2024_02-32/model.h5')\n",
    " \n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(vcf_file=None, seq_file=None, joblib_file=None):\n",
    "\tif joblib_file is not None:\n",
    "\t\ttry:\n",
    "\t\t\tdata = joblib.load(joblib_file)\n",
    "\t\t\tX = data['X']\n",
    "\t\t\ty = label2onehot(data['activate_score'])\n",
    "\t\t\treturn X, y\n",
    "\t\texcept FileNotFoundError:\n",
    "\t\t\tprint(f\"File {joblib_file} not found.\")\n",
    "\t\t\treturn None, None\n",
    "\telif seq_file is not None:\n",
    "\t\ttry:\n",
    "\t\t\tsample_seq = {}\n",
    "\t\t\twith open(seq_file, 'r') as f:\n",
    "\t\t\t\tfor line in f:\n",
    "\t\t\t\t\tfields = line.split()\n",
    "\t\t\t\t\tseqs_hap1 = [int(x) for x in fields[1].split(',')]\n",
    "\t\t\t\t\tseqs_hap2 = [int(x) for x in fields[2].split(',')]\n",
    "\t\t\t\t\n",
    "\t\t\t\t\tsample_seq[fields[0]] = [seqs_hap1, seqs_hap2]\n",
    "\t\t\tprint(sample_seq.keys())\n",
    "\t\t\t# seqs = content.split() \n",
    "\t\n",
    "\t\t\t# seq_data = {seqs[0]: [[seqs[1]], [seqs[2]]]}\n",
    "\t\t\t# print(np.array(seq_data[seqs[0]]))\n",
    "\t\t\treturn vcf2onehot.format_seqs(sample_seq)['X']\n",
    "\t\t\t\t\n",
    "\t\texcept FileNotFoundError:\n",
    "\t\t\tprint(f\"File {seq_file} not found.\")\n",
    "\telif vcf_file is not None:\n",
    "\t\ttry:\n",
    "\t\t\tseqs = vcf2onehot.build_seqs(vcf_file)\n",
    "\t\t\treturn vcf2onehot.format_seqs(seqs)['X']\n",
    "\t\texcept FileNotFoundError:\n",
    "\t\t\tprint(f\"File {seq_file} not found.\")\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(predictions: np.array):\n",
    "    dict_class = {0: 0, 1: 0.5, 2: 1, 3: 1.5, 4: 2}\n",
    "    \n",
    "    mapped_results = [dict_class[pred] for pred in predictions]\n",
    "    return mapped_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['HG00276', 'HG00436', 'HG00589', 'HG01190', 'NA06991', 'NA07000', 'NA07019', 'NA07029', 'NA07055', 'NA07056', 'NA07348', 'NA07357', 'NA10831', 'NA10847', 'NA10851', 'NA10854', 'NA11832', 'NA11839', 'NA11993', 'NA12003', 'NA12006', 'NA12145', 'NA12156', 'NA12717', 'NA12813', 'NA12873', 'NA18484', 'NA18509', 'NA18518', 'NA18519', 'NA18524', 'NA18526', 'NA18540', 'NA18544', 'NA18552', 'NA18564', 'NA18565', 'NA18617', 'NA18855', 'NA18861', 'NA18868', 'NA18942', 'NA18952', 'NA18959', 'NA18966', 'NA18973', 'NA18980', 'NA18992', 'NA19003', 'NA19007', 'NA19095', 'NA19109', 'NA19122', 'NA19143', 'NA19147', 'NA19174', 'NA19176', 'NA19178', 'NA19207', 'NA19213', 'NA19226', 'NA19239', 'NA19789', 'NA19819', 'NA19908', 'NA19917', 'NA19920', 'NA20296', 'NA20509', 'NA21781'])\n"
     ]
    }
   ],
   "source": [
    "X = get_data(seq_file='../data/PRJEB19931.seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 14868, 13)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 2970, 70)          17360     \n",
      "                                                                 \n",
      " batch_1 (BatchNormalizatio  (None, 2970, 70)          280       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " relu_1 (ReLU)               (None, 2970, 70)          0         \n",
      "                                                                 \n",
      " maxpooling_1 (MaxPooling1D  (None, 990, 70)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 196, 46)           35466     \n",
      "                                                                 \n",
      " batch_2 (BatchNormalizatio  (None, 196, 46)           184       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " relu_2 (ReLU)               (None, 196, 46)           0         \n",
      "                                                                 \n",
      " maxpooling_2 (MaxPooling1D  (None, 49, 46)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 9, 46)             14858     \n",
      "                                                                 \n",
      " batch_3 (BatchNormalizatio  (None, 9, 46)             184       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " relu_3 (ReLU)               (None, 9, 46)             0         \n",
      "                                                                 \n",
      " maxpooling_3 (MaxPooling1D  (None, 2, 46)             0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 92)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2976      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71473 (279.19 KB)\n",
      "Trainable params: 71149 (277.93 KB)\n",
      "Non-trainable params: 324 (1.27 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = get_data(joblib_file='../data/input_data/batch_126.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\ml-hus\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "16/16 [==============================] - 2s 38ms/step - loss: 0.0317 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03168383985757828, 0.9940000176429749]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.23991477e-02, 1.01728465e-05, 9.66758251e-01, 3.96954747e-05,\n",
       "        7.92718900e-04],\n",
       "       [2.63585425e-05, 6.97078349e-06, 9.99965906e-01, 6.33612501e-07,\n",
       "        8.36593728e-08],\n",
       "       [5.07644882e-06, 1.78142334e-04, 9.99796093e-01, 2.02863030e-05,\n",
       "        3.86227299e-07],\n",
       "       [1.85539350e-02, 4.15298418e-05, 9.81260300e-01, 2.10658163e-05,\n",
       "        1.23206439e-04],\n",
       "       [4.50947955e-02, 3.96103802e-04, 9.54441905e-01, 6.53739262e-05,\n",
       "        1.84414023e-06],\n",
       "       [3.16594414e-05, 7.16761127e-03, 9.92539227e-01, 2.56726431e-04,\n",
       "        4.83209260e-06],\n",
       "       [1.91778727e-02, 1.64266512e-05, 9.80794728e-01, 7.40912947e-06,\n",
       "        3.52272264e-06],\n",
       "       [2.63512247e-05, 5.47488825e-03, 9.94230866e-01, 2.67089141e-04,\n",
       "        8.32010301e-07],\n",
       "       [1.99344698e-02, 1.70503365e-04, 9.79056954e-01, 6.01309934e-04,\n",
       "        2.36722975e-04],\n",
       "       [7.01119425e-05, 9.86875035e-04, 9.98648584e-01, 2.72147183e-04,\n",
       "        2.22271483e-05],\n",
       "       [5.20025313e-01, 3.53824973e-01, 1.24965429e-01, 1.18432846e-03,\n",
       "        1.83749782e-09],\n",
       "       [5.37826478e-01, 3.46644044e-01, 1.14170976e-01, 1.35844352e-03,\n",
       "        1.80520388e-09],\n",
       "       [4.74481843e-03, 1.72876225e-05, 9.95079041e-01, 1.05730360e-05,\n",
       "        1.48288382e-04],\n",
       "       [4.07171774e-06, 1.63545720e-02, 9.81887996e-01, 1.75216887e-03,\n",
       "        1.23459733e-06],\n",
       "       [2.12482542e-01, 2.77178176e-03, 7.84521103e-01, 2.24279211e-04,\n",
       "        3.33818150e-07],\n",
       "       [3.56252044e-01, 2.45846259e-05, 6.43677294e-01, 4.34327376e-06,\n",
       "        4.16903968e-05],\n",
       "       [1.91778727e-02, 1.64266512e-05, 9.80794728e-01, 7.40912947e-06,\n",
       "        3.52272264e-06],\n",
       "       [8.22934180e-06, 7.91992247e-03, 9.91507769e-01, 5.63791429e-04,\n",
       "        2.96020630e-07],\n",
       "       [4.84865814e-01, 7.06299469e-02, 4.43766892e-01, 7.37269351e-04,\n",
       "        9.83853283e-08],\n",
       "       [6.24993627e-05, 5.63434558e-04, 9.99129593e-01, 2.11460632e-04,\n",
       "        3.30160146e-05],\n",
       "       [1.34477034e-06, 3.43152118e-04, 9.93969798e-01, 4.77580680e-03,\n",
       "        9.10000934e-04],\n",
       "       [1.12179611e-02, 1.46299877e-04, 9.88569260e-01, 6.15809477e-05,\n",
       "        4.93702782e-06],\n",
       "       [4.57371399e-02, 4.17492760e-04, 9.53777194e-01, 6.63959072e-05,\n",
       "        1.73164699e-06],\n",
       "       [1.90567644e-03, 8.99341702e-01, 9.26364362e-02, 6.11625146e-03,\n",
       "        4.62790084e-10],\n",
       "       [7.01119425e-05, 9.86875035e-04, 9.98648584e-01, 2.72147183e-04,\n",
       "        2.22271483e-05],\n",
       "       [4.76330519e-01, 3.98753226e-01, 1.23460926e-01, 1.45531970e-03,\n",
       "        2.99960806e-10],\n",
       "       [3.36497038e-07, 6.66274363e-03, 9.93067980e-01, 2.60941306e-04,\n",
       "        7.94025891e-06],\n",
       "       [7.83372286e-07, 5.66068536e-07, 9.99864936e-01, 1.77541608e-06,\n",
       "        1.31821391e-04],\n",
       "       [2.94687989e-11, 1.32098736e-04, 9.60765839e-01, 2.62265448e-02,\n",
       "        1.28755337e-02],\n",
       "       [1.38165068e-03, 6.71578618e-06, 9.98327911e-01, 1.37131123e-04,\n",
       "        1.46607039e-04],\n",
       "       [2.35767820e-05, 1.07167736e-07, 9.99791563e-01, 5.71495366e-06,\n",
       "        1.78990624e-04],\n",
       "       [2.90746193e-05, 3.54701172e-07, 9.99899268e-01, 7.95609685e-06,\n",
       "        6.33317104e-05],\n",
       "       [2.15823206e-06, 1.26422150e-04, 9.97478426e-01, 1.63833250e-03,\n",
       "        7.54727342e-04],\n",
       "       [1.03994284e-06, 1.58190087e-04, 9.96279538e-01, 2.36441870e-03,\n",
       "        1.19685184e-03],\n",
       "       [1.52740995e-05, 7.40412297e-03, 9.92075562e-01, 5.04571886e-04,\n",
       "        4.84348561e-07],\n",
       "       [5.06094102e-06, 2.66123185e-04, 9.98096406e-01, 1.31464505e-03,\n",
       "        3.17719649e-04],\n",
       "       [2.07679750e-05, 1.96295650e-06, 9.32842553e-01, 3.20016639e-04,\n",
       "        6.68148175e-02],\n",
       "       [1.99483675e-05, 1.69655584e-06, 9.32141304e-01, 3.06777714e-04,\n",
       "        6.75303042e-02],\n",
       "       [1.57021290e-07, 2.76367262e-10, 5.81695020e-01, 1.56035028e-07,\n",
       "        4.18304682e-01],\n",
       "       [2.66958182e-07, 3.71590868e-04, 9.56770301e-01, 4.23593074e-02,\n",
       "        4.98526962e-04],\n",
       "       [5.63813264e-05, 2.90853222e-07, 9.99451220e-01, 6.83579799e-07,\n",
       "        4.91400831e-04],\n",
       "       [9.76376643e-04, 5.65378832e-06, 9.99015689e-01, 1.51181973e-06,\n",
       "        8.19571540e-07],\n",
       "       [8.12003971e-04, 9.12755968e-06, 9.99172211e-01, 5.50488312e-06,\n",
       "        1.15881335e-06],\n",
       "       [7.28809437e-06, 2.14454791e-04, 9.98620033e-01, 8.65828944e-04,\n",
       "        2.92326818e-04],\n",
       "       [4.84193697e-06, 2.11503860e-02, 9.78228331e-01, 6.16266683e-04,\n",
       "        2.22560047e-07],\n",
       "       [1.84488745e-05, 8.24325811e-03, 9.91193473e-01, 5.44354203e-04,\n",
       "        4.42903257e-07],\n",
       "       [4.45690785e-06, 3.10546515e-04, 9.98383045e-01, 1.02713029e-03,\n",
       "        2.74876104e-04],\n",
       "       [6.06141329e-01, 2.49870822e-01, 1.43096730e-01, 8.91156960e-04,\n",
       "        7.93623611e-10],\n",
       "       [5.49643517e-01, 3.17975253e-01, 1.31555349e-01, 8.25774274e-04,\n",
       "        4.63524386e-10],\n",
       "       [5.49643517e-01, 3.17975253e-01, 1.31555349e-01, 8.25774274e-04,\n",
       "        4.63524386e-10],\n",
       "       [4.35706097e-05, 7.41824260e-05, 9.85558271e-01, 3.39343096e-03,\n",
       "        1.09305196e-02],\n",
       "       [8.62616556e-09, 9.17198253e-04, 9.82600272e-01, 1.57716628e-02,\n",
       "        7.10900873e-04],\n",
       "       [1.42446770e-05, 7.96519203e-07, 9.99965668e-01, 2.62152821e-06,\n",
       "        1.65983311e-05],\n",
       "       [1.72142336e-05, 7.15817223e-05, 9.86566365e-01, 8.72445293e-04,\n",
       "        1.24724424e-02],\n",
       "       [8.12003971e-04, 9.12755968e-06, 9.99172211e-01, 5.50488312e-06,\n",
       "        1.15881335e-06],\n",
       "       [1.73397173e-04, 9.32180683e-06, 9.99788940e-01, 2.87253647e-06,\n",
       "        2.54789957e-05],\n",
       "       [1.33074163e-05, 8.86285398e-03, 9.90565300e-01, 5.58019558e-04,\n",
       "        4.66273690e-07],\n",
       "       [3.60417232e-07, 7.26836475e-08, 9.99738395e-01, 1.37694342e-05,\n",
       "        2.47414922e-04],\n",
       "       [2.98256473e-05, 1.38717674e-04, 9.99525428e-01, 1.70772022e-04,\n",
       "        1.35355498e-04],\n",
       "       [1.48885192e-06, 1.60947184e-08, 9.12492335e-01, 1.25515567e-06,\n",
       "        8.75048712e-02],\n",
       "       [1.31894019e-03, 9.41105736e-06, 9.98667002e-01, 4.21574214e-06,\n",
       "        4.72508987e-07],\n",
       "       [1.16369733e-06, 8.09269659e-06, 9.99990225e-01, 3.04075087e-07,\n",
       "        2.92941678e-07],\n",
       "       [4.73474115e-01, 2.72487462e-01, 2.52719581e-01, 1.31887279e-03,\n",
       "        9.11798970e-10],\n",
       "       [6.70973986e-06, 3.04082496e-04, 9.98276114e-01, 1.12382229e-03,\n",
       "        2.89293006e-04],\n",
       "       [1.03786160e-05, 1.24075568e-05, 9.90754366e-01, 3.57733894e-04,\n",
       "        8.86516739e-03],\n",
       "       [1.34613572e-06, 4.16024523e-06, 9.99994159e-01, 1.52386164e-07,\n",
       "        2.52378669e-07],\n",
       "       [3.66377062e-05, 2.09894111e-08, 9.99909520e-01, 2.74550558e-07,\n",
       "        5.35878389e-05],\n",
       "       [2.58608470e-05, 4.47420935e-05, 9.99701560e-01, 5.90961245e-05,\n",
       "        1.68774073e-04],\n",
       "       [6.79618825e-05, 5.28570905e-04, 9.99151468e-01, 2.16479399e-04,\n",
       "        3.55003831e-05],\n",
       "       [7.01119425e-05, 9.86875035e-04, 9.98648584e-01, 2.72147183e-04,\n",
       "        2.22271483e-05]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_class = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0.5,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317 1406\n"
     ]
    }
   ],
   "source": [
    "data = get_data(vcf_file='../data/simulated_cyp2d6_diplotypes/batch_500.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0,\n",
       " 0.5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1.5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1.5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0.5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 0.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 0.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 1.5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(np.argmax(model.predict(data), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-hus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
